{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training Analysis\n",
        "\n",
        "This notebook analyzes training logs and results to visualize model performance.\n",
        "\n",
        "## Objectives\n",
        "- Load training logs (JSON, CSV, or TensorBoard)\n",
        "- Plot Dice score curves (training and validation)\n",
        "- Plot loss curves (training and validation)\n",
        "- Compare validation vs training performance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'numpy'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dict, List, Optional, Tuple\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'numpy'"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "import json\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "import pandas as pd\n",
        "\n",
        "sys.path.insert(0, str(Path().absolute().parent))\n",
        "\n",
        "# For TensorBoard support (optional)\n",
        "try:\n",
        "    from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
        "    TENSORBOARD_AVAILABLE = True\n",
        "except ImportError:\n",
        "    TENSORBOARD_AVAILABLE = False\n",
        "    print(\"TensorBoard not available. Install with: pip install tensorboard\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Training Logs\n",
        "\n",
        "Load training history from JSON, CSV, or TensorBoard format.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_json_logs(json_path: Path) -> Dict:\n",
        "    \"\"\"Load training history from JSON file.\n",
        "    \n",
        "    Args:\n",
        "        json_path: Path to JSON file containing training history.\n",
        "        \n",
        "    Returns:\n",
        "        Dictionary containing training history.\n",
        "    \"\"\"\n",
        "    with open(json_path, 'r') as f:\n",
        "        history = json.load(f)\n",
        "    return history\n",
        "\n",
        "\n",
        "def load_csv_logs(csv_path: Path) -> Dict:\n",
        "    \"\"\"Load training history from CSV file.\n",
        "    \n",
        "    Args:\n",
        "        csv_path: Path to CSV file containing training history.\n",
        "        \n",
        "    Returns:\n",
        "        Dictionary containing training history.\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(csv_path)\n",
        "    history = {}\n",
        "    for col in df.columns:\n",
        "        history[col] = df[col].tolist()\n",
        "    return history\n",
        "\n",
        "\n",
        "def load_tensorboard_logs(tb_path: Path, tags: Optional[List[str]] = None) -> Dict:\n",
        "    \"\"\"Load training history from TensorBoard event files.\n",
        "    \n",
        "    Args:\n",
        "        tb_path: Path to TensorBoard log directory.\n",
        "        tags: Optional list of tags to extract (default: all).\n",
        "        \n",
        "    Returns:\n",
        "        Dictionary containing training history.\n",
        "    \"\"\"\n",
        "    if not TENSORBOARD_AVAILABLE:\n",
        "        raise ImportError(\"TensorBoard is not available. Install with: pip install tensorboard\")\n",
        "    \n",
        "    ea = EventAccumulator(str(tb_path))\n",
        "    ea.Reload()\n",
        "    \n",
        "    history = {}\n",
        "    available_tags = ea.Tags()['scalars']\n",
        "    \n",
        "    if tags is None:\n",
        "        tags = available_tags\n",
        "    \n",
        "    for tag in tags:\n",
        "        if tag in available_tags:\n",
        "            scalar_events = ea.Scalars(tag)\n",
        "            history[tag] = [event.value for event in scalar_events]\n",
        "    \n",
        "    return history\n",
        "\n",
        "\n",
        "# Configuration: specify path to your training logs\n",
        "# Option 1: JSON file (default format from train.py)\n",
        "log_path = Path(\"../logs/training_history_20240101_120000.json\")\n",
        "\n",
        "# Option 2: CSV file (uncomment to use)\n",
        "# log_path = Path(\"../logs/training_history.csv\")\n",
        "\n",
        "# Option 3: TensorBoard directory (uncomment to use)\n",
        "# log_path = Path(\"../logs/tensorboard\")\n",
        "\n",
        "# Load logs\n",
        "print(f\"Loading logs from: {log_path}\")\n",
        "\n",
        "if log_path.is_dir():\n",
        "    # TensorBoard format\n",
        "    if TENSORBOARD_AVAILABLE:\n",
        "        history = load_tensorboard_logs(log_path)\n",
        "        print(\"Loaded TensorBoard logs\")\n",
        "    else:\n",
        "        raise ImportError(\"TensorBoard is not available\")\n",
        "elif log_path.suffix == '.json':\n",
        "    # JSON format\n",
        "    if log_path.exists():\n",
        "        history = load_json_logs(log_path)\n",
        "        print(\"Loaded JSON logs\")\n",
        "    else:\n",
        "        print(f\"ERROR: Log file not found at {log_path}\")\n",
        "        print(\"Please run training first or specify correct path.\")\n",
        "        history = None\n",
        "elif log_path.suffix == '.csv':\n",
        "    # CSV format\n",
        "    if log_path.exists():\n",
        "        history = load_csv_logs(log_path)\n",
        "        print(\"Loaded CSV logs\")\n",
        "    else:\n",
        "        print(f\"ERROR: Log file not found at {log_path}\")\n",
        "        history = None\n",
        "else:\n",
        "    print(f\"ERROR: Unsupported file format: {log_path.suffix}\")\n",
        "    history = None\n",
        "\n",
        "# Display available metrics\n",
        "if history is not None:\n",
        "    print(f\"\\nAvailable metrics: {list(history.keys())}\")\n",
        "    print(f\"Number of epochs: {len(history.get('train_loss', []))}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Plot Dice Score Curves\n",
        "\n",
        "Visualize Dice score evolution for training and validation sets.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_dice_curves(history: Dict, save_path: Optional[Path] = None):\n",
        "    \"\"\"Plot Dice score curves for training and validation.\n",
        "    \n",
        "    Args:\n",
        "        history: Training history dictionary.\n",
        "        save_path: Optional path to save the figure.\n",
        "    \"\"\"\n",
        "    epochs = range(1, len(history.get('train_dice', [])) + 1)\n",
        "    \n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "    \n",
        "    # Training Dice\n",
        "    if 'train_dice' in history and len(history['train_dice']) > 0:\n",
        "        axes[0].plot(epochs, history['train_dice'], 'b-', label='Training Dice', linewidth=2)\n",
        "        axes[0].set_xlabel('Epoch')\n",
        "        axes[0].set_ylabel('Dice Score')\n",
        "        axes[0].set_title('Training Dice Score')\n",
        "        axes[0].grid(True, alpha=0.3)\n",
        "        axes[0].legend()\n",
        "        axes[0].set_ylim([0, 1])\n",
        "        \n",
        "        # Add final value annotation\n",
        "        final_dice = history['train_dice'][-1]\n",
        "        axes[0].annotate(f'Final: {final_dice:.4f}', \n",
        "                         xy=(len(epochs), final_dice),\n",
        "                         xytext=(len(epochs) * 0.7, final_dice + 0.1),\n",
        "                         arrowprops=dict(arrowstyle='->', color='blue'))\n",
        "    else:\n",
        "        axes[0].text(0.5, 0.5, 'No training Dice data', \n",
        "                     ha='center', va='center', transform=axes[0].transAxes)\n",
        "        axes[0].set_title('Training Dice Score')\n",
        "    \n",
        "    # Validation Dice\n",
        "    if 'val_dice' in history and len(history['val_dice']) > 0:\n",
        "        axes[1].plot(epochs, history['val_dice'], 'r-', label='Validation Dice', linewidth=2)\n",
        "        axes[1].set_xlabel('Epoch')\n",
        "        axes[1].set_ylabel('Dice Score')\n",
        "        axes[1].set_title('Validation Dice Score')\n",
        "        axes[1].grid(True, alpha=0.3)\n",
        "        axes[1].legend()\n",
        "        axes[1].set_ylim([0, 1])\n",
        "        \n",
        "        # Add final value annotation\n",
        "        final_dice = history['val_dice'][-1]\n",
        "        best_dice = max(history['val_dice'])\n",
        "        best_epoch = history['val_dice'].index(best_dice) + 1\n",
        "        axes[1].annotate(f'Final: {final_dice:.4f}', \n",
        "                         xy=(len(epochs), final_dice),\n",
        "                         xytext=(len(epochs) * 0.7, final_dice + 0.1),\n",
        "                         arrowprops=dict(arrowstyle='->', color='red'))\n",
        "        axes[1].annotate(f'Best: {best_dice:.4f} (Epoch {best_epoch})', \n",
        "                         xy=(best_epoch, best_dice),\n",
        "                         xytext=(best_epoch, best_dice + 0.15),\n",
        "                         arrowprops=dict(arrowstyle='->', color='green'))\n",
        "    else:\n",
        "        axes[1].text(0.5, 0.5, 'No validation Dice data', \n",
        "                     ha='center', va='center', transform=axes[1].transAxes)\n",
        "        axes[1].set_title('Validation Dice Score')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    \n",
        "    if save_path:\n",
        "        save_path = Path(save_path)\n",
        "        save_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "        print(f\"Figure saved to {save_path}\")\n",
        "    else:\n",
        "        plt.show()\n",
        "    \n",
        "    plt.close()\n",
        "\n",
        "if history is not None:\n",
        "    plot_dice_curves(history)\n",
        "else:\n",
        "    print(\"Cannot plot Dice curves: history not loaded.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_loss_curves(history: Dict, save_path: Optional[Path] = None):\n",
        "    \"\"\"Plot loss curves for training and validation.\n",
        "    \n",
        "    Args:\n",
        "        history: Training history dictionary.\n",
        "        save_path: Optional path to save the figure.\n",
        "    \"\"\"\n",
        "    epochs = range(1, len(history.get('train_loss', [])) + 1)\n",
        "    \n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "    \n",
        "    # Training Loss\n",
        "    if 'train_loss' in history and len(history['train_loss']) > 0:\n",
        "        axes[0].plot(epochs, history['train_loss'], 'b-', label='Training Loss', linewidth=2)\n",
        "        axes[0].set_xlabel('Epoch')\n",
        "        axes[0].set_ylabel('Loss')\n",
        "        axes[0].set_title('Training Loss')\n",
        "        axes[0].grid(True, alpha=0.3)\n",
        "        axes[0].legend()\n",
        "        \n",
        "        # Add final value annotation\n",
        "        final_loss = history['train_loss'][-1]\n",
        "        axes[0].annotate(f'Final: {final_loss:.4f}', \n",
        "                         xy=(len(epochs), final_loss),\n",
        "                         xytext=(len(epochs) * 0.7, final_loss * 1.1),\n",
        "                         arrowprops=dict(arrowstyle='->', color='blue'))\n",
        "    else:\n",
        "        axes[0].text(0.5, 0.5, 'No training loss data', \n",
        "                     ha='center', va='center', transform=axes[0].transAxes)\n",
        "        axes[0].set_title('Training Loss')\n",
        "    \n",
        "    # Validation Loss\n",
        "    if 'val_loss' in history and len(history['val_loss']) > 0:\n",
        "        axes[1].plot(epochs, history['val_loss'], 'r-', label='Validation Loss', linewidth=2)\n",
        "        axes[1].set_xlabel('Epoch')\n",
        "        axes[1].set_ylabel('Loss')\n",
        "        axes[1].set_title('Validation Loss')\n",
        "        axes[1].grid(True, alpha=0.3)\n",
        "        axes[1].legend()\n",
        "        \n",
        "        # Add final value annotation\n",
        "        final_loss = history['val_loss'][-1]\n",
        "        best_loss = min(history['val_loss'])\n",
        "        best_epoch = history['val_loss'].index(best_loss) + 1\n",
        "        axes[1].annotate(f'Final: {final_loss:.4f}', \n",
        "                         xy=(len(epochs), final_loss),\n",
        "                         xytext=(len(epochs) * 0.7, final_loss * 1.1),\n",
        "                         arrowprops=dict(arrowstyle='->', color='red'))\n",
        "        axes[1].annotate(f'Best: {best_loss:.4f} (Epoch {best_epoch})', \n",
        "                         xy=(best_epoch, best_loss),\n",
        "                         xytext=(best_epoch, best_loss * 1.2),\n",
        "                         arrowprops=dict(arrowstyle='->', color='green'))\n",
        "    else:\n",
        "        axes[1].text(0.5, 0.5, 'No validation loss data', \n",
        "                     ha='center', va='center', transform=axes[1].transAxes)\n",
        "        axes[1].set_title('Validation Loss')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    \n",
        "    if save_path:\n",
        "        save_path = Path(save_path)\n",
        "        save_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "        print(f\"Figure saved to {save_path}\")\n",
        "    else:\n",
        "        plt.show()\n",
        "    \n",
        "    plt.close()\n",
        "\n",
        "if history is not None:\n",
        "    plot_loss_curves(history)\n",
        "else:\n",
        "    print(\"Cannot plot loss curves: history not loaded.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Compare Training vs Validation\n",
        "\n",
        "Side-by-side comparison of training and validation performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_training_vs_validation(history: Dict, save_path: Optional[Path] = None):\n",
        "    \"\"\"Plot training vs validation comparison for Dice and Loss.\n",
        "    \n",
        "    Args:\n",
        "        history: Training history dictionary.\n",
        "        save_path: Optional path to save the figure.\n",
        "    \"\"\"\n",
        "    epochs = range(1, len(history.get('train_loss', [])) + 1)\n",
        "    \n",
        "    fig, axes = plt.subplots(2, 1, figsize=(12, 10))\n",
        "    \n",
        "    # Dice comparison\n",
        "    if 'train_dice' in history and 'val_dice' in history:\n",
        "        if len(history['train_dice']) > 0 and len(history['val_dice']) > 0:\n",
        "            axes[0].plot(epochs, history['train_dice'], 'b-', label='Training Dice', linewidth=2, alpha=0.7)\n",
        "            axes[0].plot(epochs, history['val_dice'], 'r-', label='Validation Dice', linewidth=2, alpha=0.7)\n",
        "            axes[0].set_xlabel('Epoch')\n",
        "            axes[0].set_ylabel('Dice Score')\n",
        "            axes[0].set_title('Training vs Validation - Dice Score')\n",
        "            axes[0].grid(True, alpha=0.3)\n",
        "            axes[0].legend()\n",
        "            axes[0].set_ylim([0, 1])\n",
        "            \n",
        "            # Add statistics\n",
        "            train_final = history['train_dice'][-1]\n",
        "            val_final = history['val_dice'][-1]\n",
        "            val_best = max(history['val_dice'])\n",
        "            axes[0].text(0.02, 0.98, \n",
        "                        f'Train Final: {train_final:.4f}\\nVal Final: {val_final:.4f}\\nVal Best: {val_best:.4f}',\n",
        "                        transform=axes[0].transAxes,\n",
        "                        verticalalignment='top',\n",
        "                        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
        "        else:\n",
        "            axes[0].text(0.5, 0.5, 'No Dice data available', \n",
        "                       ha='center', va='center', transform=axes[0].transAxes)\n",
        "            axes[0].set_title('Training vs Validation - Dice Score')\n",
        "    else:\n",
        "        axes[0].text(0.5, 0.5, 'No Dice data available', \n",
        "                   ha='center', va='center', transform=axes[0].transAxes)\n",
        "        axes[0].set_title('Training vs Validation - Dice Score')\n",
        "    \n",
        "    # Loss comparison\n",
        "    if 'train_loss' in history and 'val_loss' in history:\n",
        "        if len(history['train_loss']) > 0 and len(history['val_loss']) > 0:\n",
        "            axes[1].plot(epochs, history['train_loss'], 'b-', label='Training Loss', linewidth=2, alpha=0.7)\n",
        "            axes[1].plot(epochs, history['val_loss'], 'r-', label='Validation Loss', linewidth=2, alpha=0.7)\n",
        "            axes[1].set_xlabel('Epoch')\n",
        "            axes[1].set_ylabel('Loss')\n",
        "            axes[1].set_title('Training vs Validation - Loss')\n",
        "            axes[1].grid(True, alpha=0.3)\n",
        "            axes[1].legend()\n",
        "            \n",
        "            # Add statistics\n",
        "            train_final = history['train_loss'][-1]\n",
        "            val_final = history['val_loss'][-1]\n",
        "            val_best = min(history['val_loss'])\n",
        "            axes[1].text(0.02, 0.98, \n",
        "                        f'Train Final: {train_final:.4f}\\nVal Final: {val_final:.4f}\\nVal Best: {val_best:.4f}',\n",
        "                        transform=axes[1].transAxes,\n",
        "                        verticalalignment='top',\n",
        "                        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
        "        else:\n",
        "            axes[1].text(0.5, 0.5, 'No loss data available', \n",
        "                       ha='center', va='center', transform=axes[1].transAxes)\n",
        "            axes[1].set_title('Training vs Validation - Loss')\n",
        "    else:\n",
        "        axes[1].text(0.5, 0.5, 'No loss data available', \n",
        "                   ha='center', va='center', transform=axes[1].transAxes)\n",
        "        axes[1].set_title('Training vs Validation - Loss')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    \n",
        "    if save_path:\n",
        "        save_path = Path(save_path)\n",
        "        save_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "        print(f\"Figure saved to {save_path}\")\n",
        "    else:\n",
        "        plt.show()\n",
        "    \n",
        "    plt.close()\n",
        "\n",
        "if history is not None:\n",
        "    plot_training_vs_validation(history)\n",
        "else:\n",
        "    print(\"Cannot plot comparison: history not loaded.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Additional Metrics\n",
        "\n",
        "Visualize additional metrics like IoU and learning rate.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_additional_metrics(history: Dict, save_path: Optional[Path] = None):\n",
        "    \"\"\"Plot additional metrics: IoU and learning rate.\n",
        "    \n",
        "    Args:\n",
        "        history: Training history dictionary.\n",
        "        save_path: Optional path to save the figure.\n",
        "    \"\"\"\n",
        "    epochs = range(1, len(history.get('train_loss', [])) + 1)\n",
        "    \n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "    \n",
        "    # IoU scores\n",
        "    if 'train_iou' in history or 'val_iou' in history:\n",
        "        if 'train_iou' in history and len(history['train_iou']) > 0:\n",
        "            axes[0].plot(epochs, history['train_iou'], 'b-', label='Training IoU', linewidth=2, alpha=0.7)\n",
        "        if 'val_iou' in history and len(history['val_iou']) > 0:\n",
        "            axes[0].plot(epochs, history['val_iou'], 'r-', label='Validation IoU', linewidth=2, alpha=0.7)\n",
        "        \n",
        "        axes[0].set_xlabel('Epoch')\n",
        "        axes[0].set_ylabel('IoU Score')\n",
        "        axes[0].set_title('IoU Score Evolution')\n",
        "        axes[0].grid(True, alpha=0.3)\n",
        "        axes[0].legend()\n",
        "        axes[0].set_ylim([0, 1])\n",
        "    else:\n",
        "        axes[0].text(0.5, 0.5, 'No IoU data available', \n",
        "                   ha='center', va='center', transform=axes[0].transAxes)\n",
        "        axes[0].set_title('IoU Score Evolution')\n",
        "    \n",
        "    # Learning rate\n",
        "    if 'learning_rate' in history and len(history['learning_rate']) > 0:\n",
        "        axes[1].plot(epochs, history['learning_rate'], 'g-', label='Learning Rate', linewidth=2)\n",
        "        axes[1].set_xlabel('Epoch')\n",
        "        axes[1].set_ylabel('Learning Rate')\n",
        "        axes[1].set_title('Learning Rate Schedule')\n",
        "        axes[1].grid(True, alpha=0.3)\n",
        "        axes[1].legend()\n",
        "        axes[1].set_yscale('log')\n",
        "        \n",
        "        # Add final value annotation\n",
        "        final_lr = history['learning_rate'][-1]\n",
        "        initial_lr = history['learning_rate'][0]\n",
        "        axes[1].annotate(f'Initial: {initial_lr:.2e}\\nFinal: {final_lr:.2e}', \n",
        "                        xy=(len(epochs), final_lr),\n",
        "                        xytext=(len(epochs) * 0.7, final_lr * 2),\n",
        "                        arrowprops=dict(arrowstyle='->', color='green'))\n",
        "    else:\n",
        "        axes[1].text(0.5, 0.5, 'No learning rate data available', \n",
        "                   ha='center', va='center', transform=axes[1].transAxes)\n",
        "        axes[1].set_title('Learning Rate Schedule')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    \n",
        "    if save_path:\n",
        "        save_path = Path(save_path)\n",
        "        save_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "        print(f\"Figure saved to {save_path}\")\n",
        "    else:\n",
        "        plt.show()\n",
        "    \n",
        "    plt.close()\n",
        "\n",
        "if history is not None:\n",
        "    plot_additional_metrics(history)\n",
        "else:\n",
        "    print(\"Cannot plot additional metrics: history not loaded.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Summary Statistics\n",
        "\n",
        "Display key statistics from the training run.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def print_summary_statistics(history: Dict):\n",
        "    \"\"\"Print summary statistics from training history.\n",
        "    \n",
        "    Args:\n",
        "        history: Training history dictionary.\n",
        "    \"\"\"\n",
        "    print(\"=\" * 60)\n",
        "    print(\"TRAINING SUMMARY STATISTICS\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    num_epochs = len(history.get('train_loss', []))\n",
        "    print(f\"\\nTotal epochs: {num_epochs}\")\n",
        "    \n",
        "    # Training metrics\n",
        "    if 'train_loss' in history and len(history['train_loss']) > 0:\n",
        "        print(f\"\\nTraining Loss:\")\n",
        "        print(f\"  Initial: {history['train_loss'][0]:.4f}\")\n",
        "        print(f\"  Final: {history['train_loss'][-1]:.4f}\")\n",
        "        print(f\"  Best: {min(history['train_loss']):.4f}\")\n",
        "        print(f\"  Improvement: {((history['train_loss'][0] - history['train_loss'][-1]) / history['train_loss'][0] * 100):.2f}%\")\n",
        "    \n",
        "    if 'train_dice' in history and len(history['train_dice']) > 0:\n",
        "        print(f\"\\nTraining Dice:\")\n",
        "        print(f\"  Initial: {history['train_dice'][0]:.4f}\")\n",
        "        print(f\"  Final: {history['train_dice'][-1]:.4f}\")\n",
        "        print(f\"  Best: {max(history['train_dice']):.4f}\")\n",
        "        print(f\"  Improvement: {((history['train_dice'][-1] - history['train_dice'][0]) / (1 - history['train_dice'][0]) * 100):.2f}%\")\n",
        "    \n",
        "    # Validation metrics\n",
        "    if 'val_loss' in history and len(history['val_loss']) > 0:\n",
        "        print(f\"\\nValidation Loss:\")\n",
        "        print(f\"  Initial: {history['val_loss'][0]:.4f}\")\n",
        "        print(f\"  Final: {history['val_loss'][-1]:.4f}\")\n",
        "        print(f\"  Best: {min(history['val_loss']):.4f} (Epoch {history['val_loss'].index(min(history['val_loss'])) + 1})\")\n",
        "        print(f\"  Improvement: {((history['val_loss'][0] - history['val_loss'][-1]) / history['val_loss'][0] * 100):.2f}%\")\n",
        "    \n",
        "    if 'val_dice' in history and len(history['val_dice']) > 0:\n",
        "        print(f\"\\nValidation Dice:\")\n",
        "        print(f\"  Initial: {history['val_dice'][0]:.4f}\")\n",
        "        print(f\"  Final: {history['val_dice'][-1]:.4f}\")\n",
        "        best_dice = max(history['val_dice'])\n",
        "        best_epoch = history['val_dice'].index(best_dice) + 1\n",
        "        print(f\"  Best: {best_dice:.4f} (Epoch {best_epoch})\")\n",
        "        print(f\"  Improvement: {((history['val_dice'][-1] - history['val_dice'][0]) / (1 - history['val_dice'][0]) * 100):.2f}%\")\n",
        "    \n",
        "    if 'val_iou' in history and len(history['val_iou']) > 0:\n",
        "        print(f\"\\nValidation IoU:\")\n",
        "        print(f\"  Initial: {history['val_iou'][0]:.4f}\")\n",
        "        print(f\"  Final: {history['val_iou'][-1]:.4f}\")\n",
        "        print(f\"  Best: {max(history['val_iou']):.4f}\")\n",
        "    \n",
        "    if 'learning_rate' in history and len(history['learning_rate']) > 0:\n",
        "        print(f\"\\nLearning Rate:\")\n",
        "        print(f\"  Initial: {history['learning_rate'][0]:.2e}\")\n",
        "        print(f\"  Final: {history['learning_rate'][-1]:.2e}\")\n",
        "        print(f\"  Reduction: {((history['learning_rate'][0] - history['learning_rate'][-1]) / history['learning_rate'][0] * 100):.2f}%\")\n",
        "    \n",
        "    # Overfitting check\n",
        "    if 'train_dice' in history and 'val_dice' in history:\n",
        "        if len(history['train_dice']) > 0 and len(history['val_dice']) > 0:\n",
        "            train_final = history['train_dice'][-1]\n",
        "            val_final = history['val_dice'][-1]\n",
        "            gap = train_final - val_final\n",
        "            print(f\"\\nOverfitting Analysis:\")\n",
        "            print(f\"  Train-Val Dice Gap: {gap:.4f}\")\n",
        "            if gap > 0.1:\n",
        "                print(f\"  [WARNING] Large gap detected - possible overfitting\")\n",
        "            elif gap < 0.05:\n",
        "                print(f\"  [OK] Small gap - good generalization\")\n",
        "            else:\n",
        "                print(f\"  [OK] Moderate gap - acceptable\")\n",
        "    \n",
        "    print(\"=\" * 60)\n",
        "\n",
        "if history is not None:\n",
        "    print_summary_statistics(history)\n",
        "else:\n",
        "    print(\"Cannot print statistics: history not loaded.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This notebook analyzed training logs by:\n",
        "\n",
        "1. **Loading logs**: Supported JSON, CSV, and TensorBoard formats\n",
        "2. **Dice curves**: Visualized Dice score evolution for training and validation\n",
        "3. **Loss curves**: Visualized loss evolution for training and validation\n",
        "4. **Training vs Validation**: Side-by-side comparison of performance\n",
        "5. **Additional metrics**: IoU scores and learning rate schedule\n",
        "6. **Summary statistics**: Key metrics and overfitting analysis\n",
        "\n",
        "### Key Insights:\n",
        "- Monitor Dice score to track segmentation quality\n",
        "- Compare training vs validation to detect overfitting\n",
        "- Learning rate schedule affects convergence\n",
        "- Best model checkpoint is typically at peak validation Dice\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
